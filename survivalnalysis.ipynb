{"cells":[{"cell_type":"markdown","metadata":{"id":"EL8V9kmlQDzj"},"source":["Importations\n"]},{"cell_type":"code","source":["!pip install lifelines"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"MnrPPbs7bhjO","outputId":"316f9ce7-7c95-4334-c601-1b93e36b1fd3","executionInfo":{"status":"ok","timestamp":1751059721006,"user_tz":-60,"elapsed":11654,"user":{"displayName":"Adewumi Adenike","userId":"12349155730856846617"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting lifelines\n","  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.0.2)\n","Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.15.3)\n","Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines) (2.2.2)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines) (3.10.0)\n","Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines) (1.8.0)\n","Collecting autograd-gamma>=0.3 (from lifelines)\n","  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting formulaic>=0.2.2 (from lifelines)\n","  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n","Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines)\n","  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (4.14.0)\n","Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines) (1.17.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines) (1.17.0)\n","Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: autograd-gamma\n","  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=af32ab68ba1176d29624fb2f2bdcec83ebe5585af3f98ed7293fce5571bde672\n","  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n","Successfully built autograd-gamma\n","Installing collected packages: interface-meta, autograd-gamma, formulaic, lifelines\n","Successfully installed autograd-gamma-0.5.0 formulaic-1.1.1 interface-meta-1.3.0 lifelines-0.30.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from lifelines import CoxPHFitter\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from xgboost import XGBRegressor\n","from lifelines.utils import concordance_index\n","\n","# ------------------ Load and Prep ------------------ #\n","df = pd.read_csv('/content/synthetic_nigeria_grid_data_2010_may2025_weekly_derived.csv', parse_dates=['Timestamp'])\n","df = df.sort_values('Timestamp').reset_index(drop=True)\n","\n","# Feature engineering\n","df['Month'] = df['Timestamp'].dt.month\n","df['Year'] = df['Timestamp'].dt.year\n","df['Voltage_Lag1'] = df['Voltage (V)'].shift(1)\n","df['Current_Lag1'] = df['Current (A)'].shift(1)\n","df = df.bfill()\n","\n","features = ['Voltage (V)', 'Current (A)', 'Transformer Fault', 'Line Trip Events',\n","            'Overload Condition', 'Year', 'Voltage_Lag1', 'Current_Lag1']\n","numerical = ['Voltage (V)', 'Current (A)', 'Voltage_Lag1', 'Current_Lag1']\n","\n","# Scale numerical features\n","scaler = StandardScaler()\n","df[numerical] = scaler.fit_transform(df[numerical])\n","\n","# Survival targets\n","df['Time'] = np.arange(len(df)) + 1\n","df['Event'] = df['Grid Collapse Events']\n","X = df[features]\n","y_time = df['Time'].astype(int).values\n","y_event = df['Event'].astype(int).values\n","\n","X_train, X_test, time_train, time_test, event_train, event_test = train_test_split(\n","    X, y_time, y_event, test_size=0.2, random_state=42)\n","\n","# ------------------ 1. lifelines CoxPH ------------------ #\n","cox_life = pd.concat([X_train.reset_index(drop=True),\n","                      pd.Series(time_train, name='Time'),\n","                      pd.Series(event_train, name='Event')], axis=1)\n","\n","coxph_life = CoxPHFitter()\n","coxph_life.fit(cox_life, duration_col='Time', event_col='Event')\n","y_pred_lifelines = coxph_life.predict_partial_hazard(X_test)\n","cindex_lifelines = concordance_index(time_test, -y_pred_lifelines, event_test)\n","\n","# ------------------ 2. XGBoost Survival ------------------ #\n","xgb_model = XGBRegressor(objective='survival:cox', n_estimators=100, learning_rate=0.05)\n","xgb_model.fit(X_train, time_train, sample_weight=event_train)\n","y_pred_xgb = xgb_model.predict(X_test)\n","cindex_xgb = concordance_index(time_test, -y_pred_xgb, event_test)\n","\n","# ------------------ Compare Models ------------------ #\n","print(\"\\nConcordance Index Scores\")\n","print(f\"1. lifelines CoxPH:    {cindex_lifelines:.4f}\")\n","print(f\"2. XGBoost Survival:   {cindex_xgb:.4f}\")\n","\n","# ------------------ Optional: Bar Plot ------------------ #\n","import seaborn as sns\n","\n","results = pd.DataFrame({\n","    'Model': ['Lifelines CoxPH', 'XGBoost Survival'],\n","    'Concordance Index': [cindex_lifelines, cindex_xgb]\n","}).sort_values('Concordance Index', ascending=False)\n","\n","plt.figure(figsize=(8, 4))\n","sns.barplot(data=results, x='Model', y='Concordance Index', palette='viridis')\n","plt.ylim(0.5, 1.0)\n","plt.title('Survival Model Comparison')\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"f9nTx0IMgtWA","outputId":"60601bba-2d21-491c-efe8-8ff00af22d9a","executionInfo":{"status":"error","timestamp":1751059725561,"user_tz":-60,"elapsed":4524,"user":{"displayName":"Adewumi Adenike","userId":"12349155730856846617"}}},"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/synthetic_nigeria_grid_data_2010_may2025_weekly_derived.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2-4019304506.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# ------------------ Load and Prep ------------------ #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/synthetic_nigeria_grid_data_2010_may2025_weekly_derived.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/synthetic_nigeria_grid_data_2010_may2025_weekly_derived.csv'"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from lifelines import CoxPHFitter\n","from lifelines.utils import concordance_index\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","# ------------------ Load & Preprocess ------------------ #\n","df = pd.read_csv('/content/synthetic_nigeria_grid_data_2010_may2025_daily_derived.csv', parse_dates=['Timestamp'])\n","df = df.sort_values('Timestamp').reset_index(drop=True)\n","\n","# Feature engineering\n","df['Month'] = df['Timestamp'].dt.month\n","df['Year'] = df['Timestamp'].dt.year\n","df['Voltage_Lag1'] = df['Voltage (V)'].shift(1)\n","df['Current_Lag1'] = df['Current (A)'].shift(1)\n","df = df.bfill()\n","\n","# Define features\n","features = ['Voltage (V)', 'Current (A)', 'Transformer Fault', 'Line Trip Events',\n","            'Overload Condition', 'Year', 'Voltage_Lag1', 'Current_Lag1']\n","numerical = ['Voltage (V)', 'Current (A)', 'Voltage_Lag1', 'Current_Lag1']\n","\n","# Scale numeric features\n","scaler = StandardScaler()\n","df[numerical] = scaler.fit_transform(df[numerical])\n","\n","# Survival targets\n","df['Time'] = np.arange(len(df)) + 1\n","df['Event'] = df['Grid Collapse Events']\n","\n","X = df[features]\n","y_time = df['Time'].astype(int).values\n","y_event = df['Event'].astype(int).values\n","\n","# Train/Test Split\n","X_train, X_test, time_train, time_test, event_train, event_test, df_train, df_test = train_test_split(\n","    X, y_time, y_event, df, test_size=0.2, random_state=42)\n","\n","# ------------------ Train CoxPH Model ------------------ #\n","cox_input = pd.concat([X_train.reset_index(drop=True),\n","                       pd.Series(time_train, name='Time'),\n","                       pd.Series(event_train, name='Event')], axis=1)\n","\n","coxph = CoxPHFitter(penalizer=0.1)\n","coxph.fit(cox_input, duration_col='Time', event_col='Event')\n","\n","cindex = concordance_index(time_test, -coxph.predict_partial_hazard(X_test), event_test)\n","print(f\"\\nCoxPH Concordance Index: {cindex:.4f}\")\n","\n","# ------------------ Predict Hazard & Survival ------------------ #\n","df_test = df_test.reset_index(drop=True)\n","surv_funcs = coxph.predict_survival_function(X_test)\n","df_test['Hazard_Score'] = coxph.predict_partial_hazard(X_test).values\n","df_test['Survival_At_Week_10'] = surv_funcs.loc[10].values\n","\n","# ------------------ Top-10 High-Risk Weeks ------------------ #\n","top_k = 10\n","high_risk_weeks = df_test.sort_values('Hazard_Score', ascending=False).head(top_k)\n","\n","print(f\"\\nTop-{top_k} Weeks with Highest Risk of Grid Collapse:\")\n","print(high_risk_weeks[['Timestamp', 'Hazard_Score', 'Survival_At_Week_10']])\n","\n","# ------------------ Feature Diagnosis per Risky Week ------------------ #\n","# ------------------ Feature Diagnosis per Risky Week ------------------ #\n","def generate_diagnoses_df(top_df, reference_df, feature_list, threshold_std=1.0):\n","    stats = reference_df[feature_list].agg(['mean', 'std']).T\n","    diagnosis_list = []\n","\n","    for idx, row in top_df.iterrows():\n","        timestamp = row['Timestamp']\n","        week_summary = {'Timestamp': timestamp, 'Hazard_Score': row['Hazard_Score'],\n","                        'Survival_At_Week_10': row['Survival_At_Week_10'], 'Abnormal_Features': []}\n","\n","        for feat in feature_list:\n","            val = row[feat]\n","            mean = stats.loc[feat, 'mean']\n","            std = stats.loc[feat, 'std']\n","            z = (val - mean) / std\n","\n","            if z > threshold_std:\n","                week_summary['Abnormal_Features'].append(f\"High {feat} (z={z:.2f})\")\n","            elif z < -threshold_std:\n","                week_summary['Abnormal_Features'].append(f\"Low {feat} (z={z:.2f})\")\n","\n","        week_summary['Abnormal_Features'] = ', '.join(week_summary['Abnormal_Features']) if week_summary['Abnormal_Features'] else 'None'\n","        diagnosis_list.append(week_summary)\n","\n","    return pd.DataFrame(diagnosis_list)\n","\n","diagnosis_df = generate_diagnoses_df(high_risk_weeks, df, features)\n","\n","# Show result\n","print(\"\\nDiagnosis DataFrame for Top Hazard Weeks:\")\n","print(diagnosis_df[['Timestamp', 'Hazard_Score', 'Survival_At_Week_10', 'Abnormal_Features']])"],"metadata":{"id":"h57KcvhMpRSO","executionInfo":{"status":"aborted","timestamp":1751059725592,"user_tz":-60,"elapsed":3128,"user":{"displayName":"Adewumi Adenike","userId":"12349155730856846617"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(12, 5))\n","plt.plot(df['Timestamp'], coxph.predict_partial_hazard(df[features]))\n","plt.title(\"Hazard Score Over Time (All Weeks)\")\n","plt.xlabel(\"Timestamp\")\n","plt.ylabel(\"Hazard Score\")\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"kE_r9DTfxrEf","outputId":"8252c248-8e94-4e7f-da97-742711485ec1","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1751059725622,"user_tz":-60,"elapsed":23,"user":{"displayName":"Adewumi Adenike","userId":"12349155730856846617"}}},"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'df' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3-4147710295.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoxph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_partial_hazard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hazard Score Over Time (All Weeks)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Timestamp\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hazard Score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1200x500 with 0 Axes>"]},"metadata":{}}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"_uX8BvjfYIAf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ce259b5-f444-4bbb-8534-536634807b32","executionInfo":{"status":"error","timestamp":1751059732651,"user_tz":-60,"elapsed":6938,"user":{"displayName":"Adewumi Adenike","userId":"12349155730856846617"}}},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/synthetic_nigeria_grid_data_2010_may2025_weekly_derived.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-4-1755980645.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# ------------------ 1. Load and Engineer ------------------ #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/synthetic_nigeria_grid_data_2010_may2025_weekly_derived.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m]\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/synthetic_nigeria_grid_data_2010_may2025_weekly_derived.csv'"]}],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, LSTM, Conv1D, Flatten, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras import backend as K\n","\n","# ------------------ 1. Load and Engineer ------------------ #\n","df = pd.read_csv(\"/content/synthetic_nigeria_grid_data_2010_may2025_weekly_derived.csv\", parse_dates=['Timestamp'])\n","\n","df['Year']      = df['Timestamp'].dt.year\n","df['Month']     = df['Timestamp'].dt.month\n","df['Weekday']   = df['Timestamp'].dt.weekday\n","df['IsWeekend'] = df['Weekday'].isin([5, 6]).astype(int)\n","\n","df['Next_Week_Collapse'] = df['Grid Collapse Events'].shift(-1)\n","df.dropna(inplace=True)\n","df.sort_values(\"Timestamp\", inplace=True)\n","\n","# ------------------ 2. Train/Test Split ------------------ #\n","target = 'Next_Week_Collapse'\n","X = df.drop(columns=['Timestamp', 'Grid Collapse Events', target])\n","y = df[target]\n","\n","train_mask = df['Year'] < 2023\n","X_train, y_train = X[train_mask], y[train_mask]\n","X_test,  y_test  = X[~train_mask], y[~train_mask]\n","\n","# ------------------ 3. Preprocessing ------------------ #\n","categorical = ['Transformer Fault', 'Line Trip Events', 'Overload Condition', 'IsWeekend', 'Weekday', 'Month']\n","numerical = list(set(X.columns) - set(categorical))\n","\n","preprocessor = ColumnTransformer([\n","    ('num', MinMaxScaler(), numerical),\n","    ('cat', OneHotEncoder(drop='first'), categorical)\n","])\n","\n","X_train_p = preprocessor.fit_transform(X_train)\n","X_test_p = preprocessor.transform(X_test)\n","\n","# ------------------ 4. Sequence Creation ------------------ #\n","def make_sequences(X, y, window=6):\n","    X_seq, y_seq = [], []\n","    for i in range(len(X) - window):\n","        X_seq.append(X[i:i+window])\n","        y_seq.append(y[i+window])\n","    return np.array(X_seq), np.array(y_seq)\n","\n","window_size = 24\n","X_train_seq, y_train_seq = make_sequences(X_train_p, y_train.values, window_size)\n","X_test_seq, y_test_seq = make_sequences(X_test_p, y_test.values, window_size)\n","\n","# ------------------ 5. Weighted BCE Loss ------------------ #\n","def weighted_bce(pos_weight):\n","    def loss(y_true, y_pred):\n","        bce = K.binary_crossentropy(y_true, y_pred)\n","        return K.mean(bce * (y_true * pos_weight + (1 - y_true)))\n","    return loss\n","\n","pos_weight = .0\n","loss_fn = weighted_bce(pos_weight)\n","\n","# ------------------ 6. Build Models ------------------ #\n","def build_tcn(shape):\n","    inp = Input(shape=shape)\n","    x = Conv1D(64, 3, padding='causal', activation='relu')(inp)\n","    x = Dropout(0.2)(x)\n","    x = Conv1D(32, 3, padding='causal', activation='relu')(x)\n","    x = Flatten()(x)\n","    x = Dense(64, activation='relu')(x)\n","    out = Dense(1, activation='sigmoid')(x)\n","    return Model(inp, out)\n","\n","def build_lstm(shape):\n","    inp = Input(shape=shape)\n","    x = LSTM(64, return_sequences=True)(inp)\n","    x = Dropout(0.2)(x)\n","    x = LSTM(32)(x)\n","    x = Dense(64, activation='relu')(x)\n","    out = Dense(1, activation='sigmoid')(x)\n","    return Model(inp, out)\n","\n","shape = X_train_seq.shape[1:]\n","tcn_model = build_tcn(shape)\n","lstm_model = build_lstm(shape)\n","\n","tcn_model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n","lstm_model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])\n","\n","# ------------------ 7. Train ------------------ #\n","callbacks = [EarlyStopping(patience=5, restore_best_weights=True)]\n","\n","tcn_model.fit(X_train_seq, y_train_seq, epochs=20, batch_size=32,\n","              validation_split=0.2, callbacks=callbacks, verbose=1)\n","\n","lstm_model.fit(X_train_seq, y_train_seq, epochs=20, batch_size=32,\n","               validation_split=0.2, callbacks=callbacks, verbose=1)\n","\n","# ------------------ 8. Rolling Prediction ------------------ #\n","probs, true_labels = [], []\n","\n","for i in range(len(X_test_seq)):\n","    x = X_test_seq[i:i+1]\n","    p1 = tcn_model.predict(x, verbose=0)[0][0]\n","    p2 = lstm_model.predict(x, verbose=0)[0][0]\n","    probs.append((p1 + p2) / 2)\n","    true_labels.append(y_test_seq[i])\n","\n","probs = np.array(probs)\n","y_true = np.array(true_labels).astype(int)\n","\n","# ------------------ 9. Threshold Sweep Plot ------------------ #\n","precisions, recalls, thresholds = precision_recall_curve(y_true, probs)\n","\n","'''plt.figure(figsize=(8, 5))\n","plt.plot(thresholds, precisions[:-1], label='Precision', linewidth=2)\n","plt.plot(thresholds, recalls[:-1], label='Recall', linewidth=2)\n","plt.axvline(x=0.45, color='gray', linestyle='--', label='Current Threshold (0.45)')\n","plt.title(\"Precision-Recall vs Threshold\")\n","plt.xlabel(\"Threshold\")\n","plt.ylabel(\"Score\")\n","plt.grid(True)\n","plt.legend()\n","plt.tight_layout()\n","plt.show()'''\n","\n","# ------------------ 10. Evaluation ------------------ #\n","threshold = 0.5\n","y_pred = (probs >= threshold).astype(int)\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_true, y_pred, digits=4))\n","\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=['No Collapse', 'Collapse'],\n","            yticklabels=['No Collapse', 'Collapse'])\n","plt.title(\"Confusion Matrix\")\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"GAISfHYmQCNg"},"source":["EDA"]},{"cell_type":"code","source":[],"metadata":{"id":"o__RTDBkSvpy"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}